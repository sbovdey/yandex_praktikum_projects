{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сервис по продаже автомобилей с пробегом «Не бит, не крашен» разрабатывает приложение для привлечения новых клиентов. Необходимо построить модель предсказания рыночной цены автомобиля на основе исторических данных: технические характеристики, комплектации и цены автомобилей.  \n",
    "\n",
    "Заказчику важны:\n",
    "\n",
    "- качество предсказания;\n",
    "- скорость предсказания;\n",
    "- время обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/autos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Kilometer          354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-24 11:52:17</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>2016-04-07 03:16:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-24 10:58:45</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>2016-04-07 01:46:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-14 12:52:21</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>2016-04-05 12:47:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-17 16:54:04</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-17 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>2016-03-17 17:40:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31 17:25:20</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-31 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>2016-04-06 10:17:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  2016-03-24 11:52:17    480         NaN              1993  manual      0   \n",
       "1  2016-03-24 10:58:45  18300       coupe              2011  manual    190   \n",
       "2  2016-03-14 12:52:21   9800         suv              2004    auto    163   \n",
       "3  2016-03-17 16:54:04   1500       small              2001  manual     75   \n",
       "4  2016-03-31 17:25:20   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Kilometer  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf     150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN     125000                  5  gasoline        audi         yes   \n",
       "2  grand     125000                  8  gasoline        jeep         NaN   \n",
       "3   golf     150000                  6    petrol  volkswagen          no   \n",
       "4  fabia      90000                  7  gasoline       skoda          no   \n",
       "\n",
       "           DateCreated  NumberOfPictures  PostalCode             LastSeen  \n",
       "0  2016-03-24 00:00:00                 0       70435  2016-04-07 03:16:57  \n",
       "1  2016-03-24 00:00:00                 0       66954  2016-04-07 01:46:50  \n",
       "2  2016-03-14 00:00:00                 0       90480  2016-04-05 12:47:46  \n",
       "3  2016-03-17 00:00:00                 0       91074  2016-03-17 17:40:17  \n",
       "4  2016-03-31 00:00:00                 0       60437  2016-04-06 10:17:21  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.0</td>\n",
       "      <td>354369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4416.656776</td>\n",
       "      <td>2004.234448</td>\n",
       "      <td>110.094337</td>\n",
       "      <td>128211.172535</td>\n",
       "      <td>5.714645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50508.689087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4514.158514</td>\n",
       "      <td>90.227958</td>\n",
       "      <td>189.850405</td>\n",
       "      <td>37905.341530</td>\n",
       "      <td>3.726421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25783.096248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6400.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price  RegistrationYear          Power      Kilometer  \\\n",
       "count  354369.000000     354369.000000  354369.000000  354369.000000   \n",
       "mean     4416.656776       2004.234448     110.094337  128211.172535   \n",
       "std      4514.158514         90.227958     189.850405   37905.341530   \n",
       "min         0.000000       1000.000000       0.000000    5000.000000   \n",
       "25%      1050.000000       1999.000000      69.000000  125000.000000   \n",
       "50%      2700.000000       2003.000000     105.000000  150000.000000   \n",
       "75%      6400.000000       2008.000000     143.000000  150000.000000   \n",
       "max     20000.000000       9999.000000   20000.000000  150000.000000   \n",
       "\n",
       "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
       "count      354369.000000          354369.0  354369.000000  \n",
       "mean            5.714645               0.0   50508.689087  \n",
       "std             3.726421               0.0   25783.096248  \n",
       "min             0.000000               0.0    1067.000000  \n",
       "25%             3.000000               0.0   30165.000000  \n",
       "50%             6.000000               0.0   49413.000000  \n",
       "75%             9.000000               0.0   71083.000000  \n",
       "max            12.000000               0.0   99998.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Выводы после ознакомления:\n",
    "- Всего предоставлено 354369 объектов\n",
    "- После зачитывания столбцы имеют тип либо int64, либо object. Три столбца object - это данные дата/время, без пропусков. Все остальные столбцы object - это категориальные данные и все они имеют пропуски, за исключением столбца Brand. Библиотека LightGBM самостоятельно обрабатывает пропуски в категориальных данных, но требует положительный целочисленный тип данных в категориальных столбцах. Поэтому мы преобразуем все эти столбцы в тип category с сохранением пропусков. Для обучения других моделей мы для пропусков создадим отдельную категории unknown\n",
    "- Целочисленные данные не имеют пропусков, но некоторые столбцы имеют явные ошибочные данные - годы регистрации, равные 1000 или 9999, мощности, равные 0 или 20000. Разберемся с этим на следующем этапе.\n",
    "- Столбцы PostalCode и NumberOfPictures, в котором всюду 0, не понадобятся для обучения моделей. Скорее всего, также не понадобятся некоторые или все столбцы дата/время, но решение об этом будет принято после более детального знакомства с данными в этих столбцах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Преобразование типов, обработка ошибочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим список столбцов, которые не будут использоваться при обучении моделей\n",
    "columns_to_drop = ['PostalCode', 'NumberOfPictures']\n",
    "\n",
    "# создадим список категориальных столбцов\n",
    "columns_category = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "\n",
    "# создадим список столбцов дата/время\n",
    "columns_dates = ['DateCrawled', 'DateCreated', 'LastSeen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateCrawled 2016-03-05 14:06:22 2016-04-07 14:36:58\n",
      "DateCreated 2014-03-10 00:00:00 2016-04-07 00:00:00\n",
      "LastSeen 2016-03-05 14:15:08 2016-04-07 14:58:51\n"
     ]
    }
   ],
   "source": [
    "for col in columns_dates:\n",
    "    data[col] = pd.to_datetime(data[col])\n",
    "    print(col, data[col].min(), data[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Все объекты были получены из базы в течение примерно одного месяца 2016 года (с 5 марта по 7 апреля). При этом последняя активность каждого пользователя фиксировалась в этот же период времени. Это означает, что все объекты актуальны на момент выгрузки их из базы. Это также означает, что для построения наших моделей столбцы DateCrawled и LastSeen не нужны. \n",
    "- Даты создания анкет лежат в более широком диапазоне. Возможно, в этом столбце сохранен важный признак - срок экспозиции. Создадим новый столбец DaysExposed и посмотрим распределение данных в нем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DaysExposed'] = (data['DateCrawled'] - data['DateCreated']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    354369.000000\n",
       "mean          0.086698\n",
       "std           2.135045\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max         737.000000\n",
       "Name: DaysExposed, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DaysExposed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# судя по статистикам, подавляющая часть данных - это анкеты созданные в день выгрузки, \n",
    "# посмотрим анкеты, в которых срок между датой создания и датой выгрузки превышает 30 дней\n",
    "ax = data['DaysExposed'].hist(bins=30, range=(30, 737))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['DaysExposed'] > 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Данных, в которых срок между датой создания и датой выгрузки превышает 30 дней, немного - всего 182 объекта. При этом нет достаточных оснований считать эти данные неактуальными, поскольку ранее при сравнении столбцов DateCrawled и LastSeen мы убедились, что все данные актуальны.\n",
    "- Тем не менее, учитывая, что таких данных совсем немного и по параметру DaysExposed эти данные очень сильно отличаются от всех остальных, принято решение избавиться от них.\n",
    "- Был проведен анализ всех столбцов типа дата/время. С учетом удаления данных, в которых срок между датой создания и датой выгрузки превышает 30 дней, принято решение не использовать все столбцы дата/время для обучения моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_exposed_to_be_dropped = 30\n",
    "filter = data['DaysExposed'] <= days_exposed_to_be_dropped\n",
    "data = data[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop += columns_dates\n",
    "columns_to_drop.append('DaysExposed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для визуального изучения потенциальных ошибок в некоторых целочисленных столбцах создадим соотв. функцию\n",
    "def show_outlier(col, min=None, max=None):\n",
    "    if min is not None:\n",
    "        data[(data[col] < min)][col].hist(bins=50)\n",
    "        plt.show()\n",
    "    if max is not None:\n",
    "        data[(data[col] > max)][col].hist(bins=50)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_outlier('Price', min=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "      <th>DaysExposed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-03-21 18:54:38</td>\n",
       "      <td>0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1980</td>\n",
       "      <td>manual</td>\n",
       "      <td>50</td>\n",
       "      <td>other</td>\n",
       "      <td>40000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>0</td>\n",
       "      <td>19348</td>\n",
       "      <td>2016-03-25 16:47:58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-03-26 22:06:17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>corsa</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>petrol</td>\n",
       "      <td>opel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-26</td>\n",
       "      <td>0</td>\n",
       "      <td>56412</td>\n",
       "      <td>2016-03-27 17:43:34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2016-03-29 15:48:15</td>\n",
       "      <td>1</td>\n",
       "      <td>suv</td>\n",
       "      <td>1994</td>\n",
       "      <td>manual</td>\n",
       "      <td>286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sonstige_autos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>0</td>\n",
       "      <td>53721</td>\n",
       "      <td>2016-04-06 01:44:38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2016-03-28 09:37:01</td>\n",
       "      <td>1</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1995</td>\n",
       "      <td>manual</td>\n",
       "      <td>113</td>\n",
       "      <td>e_klasse</td>\n",
       "      <td>150000</td>\n",
       "      <td>4</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>40589</td>\n",
       "      <td>2016-04-06 12:15:54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2016-03-19 18:40:12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>0</td>\n",
       "      <td>21698</td>\n",
       "      <td>2016-04-01 08:47:05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354205</th>\n",
       "      <td>2016-03-09 15:56:30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>manual</td>\n",
       "      <td>65</td>\n",
       "      <td>corsa</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>opel</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-09</td>\n",
       "      <td>0</td>\n",
       "      <td>23758</td>\n",
       "      <td>2016-03-30 11:16:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354238</th>\n",
       "      <td>2016-03-20 14:55:07</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>2002</td>\n",
       "      <td>manual</td>\n",
       "      <td>60</td>\n",
       "      <td>fiesta</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>ford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>0</td>\n",
       "      <td>33659</td>\n",
       "      <td>2016-04-06 18:45:23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354248</th>\n",
       "      <td>2016-03-24 13:48:05</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>1999</td>\n",
       "      <td>manual</td>\n",
       "      <td>53</td>\n",
       "      <td>swift</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>suzuki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>0</td>\n",
       "      <td>42329</td>\n",
       "      <td>2016-04-07 05:17:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354277</th>\n",
       "      <td>2016-03-10 22:55:50</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "      <td>1999</td>\n",
       "      <td>manual</td>\n",
       "      <td>37</td>\n",
       "      <td>arosa</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>seat</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>0</td>\n",
       "      <td>22559</td>\n",
       "      <td>2016-03-12 23:46:32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354364</th>\n",
       "      <td>2016-03-21 09:50:58</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>colt</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>mitsubishi</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2694</td>\n",
       "      <td>2016-03-21 10:42:49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12027 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateCrawled  Price VehicleType  RegistrationYear Gearbox  \\\n",
       "7      2016-03-21 18:54:38      0       sedan              1980  manual   \n",
       "40     2016-03-26 22:06:17      0         NaN              1990     NaN   \n",
       "59     2016-03-29 15:48:15      1         suv              1994  manual   \n",
       "89     2016-03-28 09:37:01      1       sedan              1995  manual   \n",
       "111    2016-03-19 18:40:12      0         NaN              2017  manual   \n",
       "...                    ...    ...         ...               ...     ...   \n",
       "354205 2016-03-09 15:56:30      0         NaN              2000  manual   \n",
       "354238 2016-03-20 14:55:07      0       small              2002  manual   \n",
       "354248 2016-03-24 13:48:05      0       small              1999  manual   \n",
       "354277 2016-03-10 22:55:50      0       small              1999  manual   \n",
       "354364 2016-03-21 09:50:58      0         NaN              2005  manual   \n",
       "\n",
       "        Power     Model  Kilometer  RegistrationMonth  FuelType  \\\n",
       "7          50     other      40000                  7    petrol   \n",
       "40          0     corsa     150000                  1    petrol   \n",
       "59        286       NaN     150000                 11       NaN   \n",
       "89        113  e_klasse     150000                  4  gasoline   \n",
       "111         0      golf       5000                 12    petrol   \n",
       "...       ...       ...        ...                ...       ...   \n",
       "354205     65     corsa     150000                  0       NaN   \n",
       "354238     60    fiesta     150000                  3    petrol   \n",
       "354248     53     swift     150000                  3    petrol   \n",
       "354277     37     arosa     150000                  7    petrol   \n",
       "354364      0      colt     150000                  7    petrol   \n",
       "\n",
       "                 Brand NotRepaired DateCreated  NumberOfPictures  PostalCode  \\\n",
       "7           volkswagen          no  2016-03-21                 0       19348   \n",
       "40                opel         NaN  2016-03-26                 0       56412   \n",
       "59      sonstige_autos         NaN  2016-03-29                 0       53721   \n",
       "89       mercedes_benz          no  2016-03-28                 0       40589   \n",
       "111         volkswagen         NaN  2016-03-19                 0       21698   \n",
       "...                ...         ...         ...               ...         ...   \n",
       "354205            opel         yes  2016-03-09                 0       23758   \n",
       "354238            ford         NaN  2016-03-20                 0       33659   \n",
       "354248          suzuki         NaN  2016-03-24                 0       42329   \n",
       "354277            seat         yes  2016-03-10                 0       22559   \n",
       "354364      mitsubishi         yes  2016-03-21                 0        2694   \n",
       "\n",
       "                  LastSeen  DaysExposed  \n",
       "7      2016-03-25 16:47:58            0  \n",
       "40     2016-03-27 17:43:34            0  \n",
       "59     2016-04-06 01:44:38            0  \n",
       "89     2016-04-06 12:15:54            0  \n",
       "111    2016-04-01 08:47:05            0  \n",
       "...                    ...          ...  \n",
       "354205 2016-03-30 11:16:08            0  \n",
       "354238 2016-04-06 18:45:23            0  \n",
       "354248 2016-04-07 05:17:24            0  \n",
       "354277 2016-03-12 23:46:32            0  \n",
       "354364 2016-03-21 10:42:49            0  \n",
       "\n",
       "[12027 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вызывают большое сомнение данные около 0, рассмотрим их\n",
    "data[(data['Price'] < 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_outlier('Price', min=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объекты с 0 (и близко к этому) ценой - явно ошибочные, возможно, владельцы сознательно не хотели указывать цену и использовали 0 как способ это сделать. Удалим такие объекты, как не не имеющие целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_min_to_be_dropped = 50\n",
    "filter = data['Price'] > price_min_to_be_dropped\n",
    "data = data[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_outlier('RegistrationYear', min=1900, max=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>DaysExposed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13692.000000</td>\n",
       "      <td>13692.000000</td>\n",
       "      <td>13692.000000</td>\n",
       "      <td>13692.000000</td>\n",
       "      <td>13692.000000</td>\n",
       "      <td>13692.0</td>\n",
       "      <td>13692.00000</td>\n",
       "      <td>13692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3342.154324</td>\n",
       "      <td>2040.714870</td>\n",
       "      <td>88.532720</td>\n",
       "      <td>132119.485831</td>\n",
       "      <td>4.817558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48513.83976</td>\n",
       "      <td>0.052585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3470.397813</td>\n",
       "      <td>366.003519</td>\n",
       "      <td>248.693865</td>\n",
       "      <td>36294.213360</td>\n",
       "      <td>3.993295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25090.76408</td>\n",
       "      <td>0.554669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1099.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28219.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46519.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4290.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66464.75000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>16011.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99994.00000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price  RegistrationYear         Power      Kilometer  \\\n",
       "count  13692.000000      13692.000000  13692.000000   13692.000000   \n",
       "mean    3342.154324       2040.714870     88.532720  132119.485831   \n",
       "std     3470.397813        366.003519    248.693865   36294.213360   \n",
       "min       55.000000       2017.000000      0.000000    5000.000000   \n",
       "25%     1099.000000       2017.000000      0.000000  125000.000000   \n",
       "50%     2000.000000       2017.000000     80.000000  150000.000000   \n",
       "75%     4290.000000       2018.000000    116.000000  150000.000000   \n",
       "max    20000.000000       9999.000000  16011.000000  150000.000000   \n",
       "\n",
       "       RegistrationMonth  NumberOfPictures   PostalCode   DaysExposed  \n",
       "count       13692.000000           13692.0  13692.00000  13692.000000  \n",
       "mean            4.817558               0.0  48513.83976      0.052585  \n",
       "std             3.993295               0.0  25090.76408      0.554669  \n",
       "min             0.000000               0.0   1067.00000      0.000000  \n",
       "25%             1.000000               0.0  28219.00000      0.000000  \n",
       "50%             4.000000               0.0  46519.00000      0.000000  \n",
       "75%             8.000000               0.0  66464.75000      0.000000  \n",
       "max            12.000000               0.0  99994.00000     25.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объектов с годом регистрации ранее 1900 явно ошибки и их немного \n",
    "# объектов с годом регистрации более 2016 года (хотя год выгрузки =2016) достаточно много ~14000\n",
    "# и почти все они имеют не явно ошибочные значения, посмотрим на них более внимательно\n",
    "data[data['RegistrationYear'] > 2016].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобладающее кол-во таких объектов имеет год регистрации 2017 или 2018 при том, что анкета и создана, и выгружена из базы в 2016 году. Кроме того, более 75% таких объектов имеют пробег от 125000 и выше, что свидетельствует о том, что автомобиль имеет приличный возраст. Будем считать, что такие объекты, как и объекты с годом регистрации ранее 1900 года, на самом деле имеют пропуск в столбцах RegistrationYear и RegistrationMonth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_outlier('Power', min=30, max=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "      <th>DaysExposed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2016-03-20 20:45:27</td>\n",
       "      <td>3950</td>\n",
       "      <td>small</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>sonstige_autos</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>0</td>\n",
       "      <td>90562</td>\n",
       "      <td>2016-04-03 04:17:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2016-03-08 20:43:16</td>\n",
       "      <td>4450</td>\n",
       "      <td>small</td>\n",
       "      <td>1971</td>\n",
       "      <td>manual</td>\n",
       "      <td>23</td>\n",
       "      <td>500</td>\n",
       "      <td>70000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>fiat</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-08</td>\n",
       "      <td>0</td>\n",
       "      <td>33729</td>\n",
       "      <td>2016-04-05 18:44:51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>2016-04-03 19:53:44</td>\n",
       "      <td>650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trabant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>0</td>\n",
       "      <td>9337</td>\n",
       "      <td>2016-04-05 20:45:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>2016-03-29 17:37:58</td>\n",
       "      <td>1990</td>\n",
       "      <td>small</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>polo</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>0</td>\n",
       "      <td>37124</td>\n",
       "      <td>2016-04-02 05:16:40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>2016-03-27 13:46:49</td>\n",
       "      <td>2300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>manual</td>\n",
       "      <td>26</td>\n",
       "      <td>601</td>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trabant</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>39443</td>\n",
       "      <td>2016-04-07 09:45:27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351682</th>\n",
       "      <td>2016-03-12 00:57:39</td>\n",
       "      <td>11500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>other</td>\n",
       "      <td>5000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>fiat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>16515</td>\n",
       "      <td>2016-04-05 19:47:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353127</th>\n",
       "      <td>2016-03-26 18:53:12</td>\n",
       "      <td>8600</td>\n",
       "      <td>convertible</td>\n",
       "      <td>2012</td>\n",
       "      <td>manual</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>3</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>sonstige_autos</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-26</td>\n",
       "      <td>0</td>\n",
       "      <td>82399</td>\n",
       "      <td>2016-04-06 08:17:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353447</th>\n",
       "      <td>2016-03-27 00:46:19</td>\n",
       "      <td>2900</td>\n",
       "      <td>small</td>\n",
       "      <td>1969</td>\n",
       "      <td>manual</td>\n",
       "      <td>18</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>petrol</td>\n",
       "      <td>fiat</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-26</td>\n",
       "      <td>0</td>\n",
       "      <td>74076</td>\n",
       "      <td>2016-03-28 17:45:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353501</th>\n",
       "      <td>2016-03-27 13:49:55</td>\n",
       "      <td>11300</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1988</td>\n",
       "      <td>manual</td>\n",
       "      <td>29</td>\n",
       "      <td>other</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>citroen</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>18347</td>\n",
       "      <td>2016-04-07 09:46:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354360</th>\n",
       "      <td>2016-04-02 20:37:03</td>\n",
       "      <td>3999</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2005</td>\n",
       "      <td>manual</td>\n",
       "      <td>3</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>bmw</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>0</td>\n",
       "      <td>81825</td>\n",
       "      <td>2016-04-06 20:47:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateCrawled  Price  VehicleType  RegistrationYear Gearbox  \\\n",
       "431    2016-03-20 20:45:27   3950        small              2004    auto   \n",
       "1235   2016-03-08 20:43:16   4450        small              1971  manual   \n",
       "1331   2016-04-03 19:53:44    650          NaN              1970     NaN   \n",
       "3349   2016-03-29 17:37:58   1990        small              2004     NaN   \n",
       "3419   2016-03-27 13:46:49   2300          NaN              2017  manual   \n",
       "...                    ...    ...          ...               ...     ...   \n",
       "351682 2016-03-12 00:57:39  11500          NaN              1800     NaN   \n",
       "353127 2016-03-26 18:53:12   8600  convertible              2012  manual   \n",
       "353447 2016-03-27 00:46:19   2900        small              1969  manual   \n",
       "353501 2016-03-27 13:49:55  11300        sedan              1988  manual   \n",
       "354360 2016-04-02 20:37:03   3999        wagon              2005  manual   \n",
       "\n",
       "        Power  Model  Kilometer  RegistrationMonth  FuelType           Brand  \\\n",
       "431         5    NaN      70000                  5  gasoline  sonstige_autos   \n",
       "1235       23    500      70000                  5    petrol            fiat   \n",
       "1331       26    NaN     100000                  5       NaN         trabant   \n",
       "3349        7   polo     150000                  5  gasoline      volkswagen   \n",
       "3419       26    601      70000                  1       NaN         trabant   \n",
       "...       ...    ...        ...                ...       ...             ...   \n",
       "351682     16  other       5000                  6    petrol            fiat   \n",
       "353127      8    NaN       5000                  3  gasoline  sonstige_autos   \n",
       "353447     18    500       5000                  8    petrol            fiat   \n",
       "353501     29  other     150000                  3    petrol         citroen   \n",
       "354360      3    3er     150000                  5  gasoline             bmw   \n",
       "\n",
       "       NotRepaired DateCreated  NumberOfPictures  PostalCode  \\\n",
       "431             no  2016-03-20                 0       90562   \n",
       "1235            no  2016-03-08                 0       33729   \n",
       "1331           NaN  2016-04-03                 0        9337   \n",
       "3349            no  2016-03-29                 0       37124   \n",
       "3419            no  2016-03-27                 0       39443   \n",
       "...            ...         ...               ...         ...   \n",
       "351682         NaN  2016-03-11                 0       16515   \n",
       "353127          no  2016-03-26                 0       82399   \n",
       "353447          no  2016-03-26                 0       74076   \n",
       "353501          no  2016-03-27                 0       18347   \n",
       "354360          no  2016-04-02                 0       81825   \n",
       "\n",
       "                  LastSeen  DaysExposed  \n",
       "431    2016-04-03 04:17:08            0  \n",
       "1235   2016-04-05 18:44:51            0  \n",
       "1331   2016-04-05 20:45:24            0  \n",
       "3349   2016-04-02 05:16:40            0  \n",
       "3419   2016-04-07 09:45:27            0  \n",
       "...                    ...          ...  \n",
       "351682 2016-04-05 19:47:27            1  \n",
       "353127 2016-04-06 08:17:29            0  \n",
       "353447 2016-03-28 17:45:04            1  \n",
       "353501 2016-04-07 09:46:17            0  \n",
       "354360 2016-04-06 20:47:12            0  \n",
       "\n",
       "[823 rows x 17 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['Power'] > 1) & (data['Power'] < 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "      <th>DaysExposed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>2016-03-22 20:52:00</td>\n",
       "      <td>3200</td>\n",
       "      <td>small</td>\n",
       "      <td>2004</td>\n",
       "      <td>manual</td>\n",
       "      <td>1398</td>\n",
       "      <td>corolla</td>\n",
       "      <td>5000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>toyota</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>22043</td>\n",
       "      <td>2016-03-22 21:43:26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>2016-03-29 19:44:48</td>\n",
       "      <td>500</td>\n",
       "      <td>wagon</td>\n",
       "      <td>1999</td>\n",
       "      <td>manual</td>\n",
       "      <td>1001</td>\n",
       "      <td>astra</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>opel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>0</td>\n",
       "      <td>33154</td>\n",
       "      <td>2016-04-06 05:44:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7720</th>\n",
       "      <td>2016-04-02 11:48:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2000</td>\n",
       "      <td>manual</td>\n",
       "      <td>1400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>honda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>0</td>\n",
       "      <td>21509</td>\n",
       "      <td>2016-04-04 09:15:26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19826</th>\n",
       "      <td>2016-03-18 23:52:30</td>\n",
       "      <td>3390</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2009</td>\n",
       "      <td>manual</td>\n",
       "      <td>1240</td>\n",
       "      <td>micra</td>\n",
       "      <td>60000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>nissan</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>22083</td>\n",
       "      <td>2016-03-31 11:16:49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>2016-03-29 17:53:17</td>\n",
       "      <td>200</td>\n",
       "      <td>small</td>\n",
       "      <td>2000</td>\n",
       "      <td>manual</td>\n",
       "      <td>1200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>4</td>\n",
       "      <td>petrol</td>\n",
       "      <td>lancia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>0</td>\n",
       "      <td>10585</td>\n",
       "      <td>2016-04-06 03:45:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345756</th>\n",
       "      <td>2016-03-30 17:56:27</td>\n",
       "      <td>850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>manual</td>\n",
       "      <td>1003</td>\n",
       "      <td>ka</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>petrol</td>\n",
       "      <td>ford</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>45891</td>\n",
       "      <td>2016-04-05 06:17:55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347016</th>\n",
       "      <td>2016-03-21 20:58:26</td>\n",
       "      <td>450</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1996</td>\n",
       "      <td>auto</td>\n",
       "      <td>1004</td>\n",
       "      <td>vectra</td>\n",
       "      <td>80000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>opel</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>0</td>\n",
       "      <td>12689</td>\n",
       "      <td>2016-03-21 20:58:26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348968</th>\n",
       "      <td>2016-04-04 18:53:25</td>\n",
       "      <td>250</td>\n",
       "      <td>small</td>\n",
       "      <td>1999</td>\n",
       "      <td>manual</td>\n",
       "      <td>1241</td>\n",
       "      <td>ypsilon</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>lancia</td>\n",
       "      <td>yes</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>28259</td>\n",
       "      <td>2016-04-04 18:53:25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351947</th>\n",
       "      <td>2016-03-07 21:36:19</td>\n",
       "      <td>1500</td>\n",
       "      <td>bus</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>1001</td>\n",
       "      <td>zafira</td>\n",
       "      <td>5000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>opel</td>\n",
       "      <td>no</td>\n",
       "      <td>2016-03-07</td>\n",
       "      <td>0</td>\n",
       "      <td>66117</td>\n",
       "      <td>2016-03-09 12:47:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354260</th>\n",
       "      <td>2016-03-09 17:59:03</td>\n",
       "      <td>399</td>\n",
       "      <td>other</td>\n",
       "      <td>1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1103</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bmw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-09</td>\n",
       "      <td>0</td>\n",
       "      <td>56235</td>\n",
       "      <td>2016-03-17 09:17:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateCrawled  Price VehicleType  RegistrationYear Gearbox  \\\n",
       "1816   2016-03-22 20:52:00   3200       small              2004  manual   \n",
       "5328   2016-03-29 19:44:48    500       wagon              1999  manual   \n",
       "7720   2016-04-02 11:48:54   1500       small              2000  manual   \n",
       "19826  2016-03-18 23:52:30   3390       sedan              2009  manual   \n",
       "21609  2016-03-29 17:53:17    200       small              2000  manual   \n",
       "...                    ...    ...         ...               ...     ...   \n",
       "345756 2016-03-30 17:56:27    850         NaN              2005  manual   \n",
       "347016 2016-03-21 20:58:26    450       sedan              1996    auto   \n",
       "348968 2016-04-04 18:53:25    250       small              1999  manual   \n",
       "351947 2016-03-07 21:36:19   1500         bus              2001  manual   \n",
       "354260 2016-03-09 17:59:03    399       other              1994     NaN   \n",
       "\n",
       "        Power    Model  Kilometer  RegistrationMonth  FuelType   Brand  \\\n",
       "1816     1398  corolla       5000                  6    petrol  toyota   \n",
       "5328     1001    astra     150000                  7    petrol    opel   \n",
       "7720     1400      NaN     150000                  0    petrol   honda   \n",
       "19826    1240    micra      60000                  3    petrol  nissan   \n",
       "21609    1200      NaN     125000                  4    petrol  lancia   \n",
       "...       ...      ...        ...                ...       ...     ...   \n",
       "345756   1003       ka       5000                 12    petrol    ford   \n",
       "347016   1004   vectra      80000                  5    petrol    opel   \n",
       "348968   1241  ypsilon     150000                  5    petrol  lancia   \n",
       "351947   1001   zafira       5000                  7  gasoline    opel   \n",
       "354260   1103      3er     150000                  0       NaN     bmw   \n",
       "\n",
       "       NotRepaired DateCreated  NumberOfPictures  PostalCode  \\\n",
       "1816            no  2016-03-22                 0       22043   \n",
       "5328           NaN  2016-03-29                 0       33154   \n",
       "7720           NaN  2016-04-02                 0       21509   \n",
       "19826           no  2016-03-18                 0       22083   \n",
       "21609          NaN  2016-03-29                 0       10585   \n",
       "...            ...         ...               ...         ...   \n",
       "345756          no  2016-03-30                 0       45891   \n",
       "347016         yes  2016-03-21                 0       12689   \n",
       "348968         yes  2016-04-04                 0       28259   \n",
       "351947          no  2016-03-07                 0       66117   \n",
       "354260         NaN  2016-03-09                 0       56235   \n",
       "\n",
       "                  LastSeen  DaysExposed  \n",
       "1816   2016-03-22 21:43:26            0  \n",
       "5328   2016-04-06 05:44:36            0  \n",
       "7720   2016-04-04 09:15:26            0  \n",
       "19826  2016-03-31 11:16:49            0  \n",
       "21609  2016-04-06 03:45:24            0  \n",
       "...                    ...          ...  \n",
       "345756 2016-04-05 06:17:55            0  \n",
       "347016 2016-03-21 20:58:26            0  \n",
       "348968 2016-04-04 18:53:25            0  \n",
       "351947 2016-03-09 12:47:08            0  \n",
       "354260 2016-03-17 09:17:08            0  \n",
       "\n",
       "[91 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['Power'] > 1000) & (data['Power'] < 1500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Подавляющее число объектов с подозрительно низкой мощностью (<30 л.с.) имеет указанную в анкете мощность = 0. Их в нашей выборке достаточно много ~40000.\n",
    "- Объектов с подозрительно высокой мощностью не так много, судя по всему, это явные ошибки (вместо л.с. указывается объем двигателя).\n",
    "- Будем считать, что объекты, в которых указанная мощность менее 30 или более 1000 л.с., имеют на самом деле пропуск в столбце Power. \n",
    "- Заполним все выявленные ошибочные значения в столбцах RegistrationYear, Power и RegistrationMonth np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_to_nan(col, min=None, max=None):\n",
    "    if min is not None:\n",
    "        data.loc[data[col] < min, col] = np.nan\n",
    "    if max is not None:\n",
    "        data.loc[data[col] > max, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим диапазоны года регистрации и мощности, выход за который мы считаем  ошибкой\n",
    "min_registration_year = 1900\n",
    "max_registration_year = 2016\n",
    "min_power = 30\n",
    "max_power = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# исправим ошибки на nan\n",
    "outlier_to_nan('RegistrationYear', min=min_registration_year, max=max_registration_year)\n",
    "outlier_to_nan('Power', min=min_power, max=max_power)\n",
    "data.loc[data['RegistrationYear'].isna(), 'RegistrationMonth'] = np.nan\n",
    "data.loc[data['RegistrationMonth'] == 0, 'RegistrationMonth'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# избавимся от столбцов, которые не будут использоваться при обучении моделей\n",
    "data = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>341438.000000</td>\n",
       "      <td>327700.000000</td>\n",
       "      <td>304962.000000</td>\n",
       "      <td>341438.000000</td>\n",
       "      <td>299193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4580.235867</td>\n",
       "      <td>2002.617620</td>\n",
       "      <td>120.654324</td>\n",
       "      <td>128480.134021</td>\n",
       "      <td>6.391908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4514.292043</td>\n",
       "      <td>6.869516</td>\n",
       "      <td>54.557570</td>\n",
       "      <td>37285.280358</td>\n",
       "      <td>3.349304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2900.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6500.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price  RegistrationYear          Power      Kilometer  \\\n",
       "count  341438.000000     327700.000000  304962.000000  341438.000000   \n",
       "mean     4580.235867       2002.617620     120.654324  128480.134021   \n",
       "std      4514.292043          6.869516      54.557570   37285.280358   \n",
       "min        55.000000       1910.000000      30.000000    5000.000000   \n",
       "25%      1200.000000       1999.000000      75.000000  125000.000000   \n",
       "50%      2900.000000       2003.000000     110.000000  150000.000000   \n",
       "75%      6500.000000       2007.000000     150.000000  150000.000000   \n",
       "max     20000.000000       2016.000000    1000.000000  150000.000000   \n",
       "\n",
       "       RegistrationMonth  \n",
       "count      299193.000000  \n",
       "mean            6.391908  \n",
       "std             3.349304  \n",
       "min             1.000000  \n",
       "25%             4.000000  \n",
       "50%             6.000000  \n",
       "75%             9.000000  \n",
       "max            12.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 341438 entries, 0 to 354368\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Price              341438 non-null  int64  \n",
      " 1   VehicleType        308614 non-null  object \n",
      " 2   RegistrationYear   327700 non-null  float64\n",
      " 3   Gearbox            324901 non-null  object \n",
      " 4   Power              304962 non-null  float64\n",
      " 5   Model              324338 non-null  object \n",
      " 6   Kilometer          341438 non-null  int64  \n",
      " 7   RegistrationMonth  299193 non-null  float64\n",
      " 8   FuelType           312876 non-null  object \n",
      " 9   Brand              341438 non-null  object \n",
      " 10  NotRepaired        276781 non-null  object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 31.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пакет LightGBM имеет свои средства для работы с категориями и пропусками,\n",
    "# поэтому далее подготовку данных для разных моделей будем осуществлять в разных df\n",
    "data_lgbm = data.copy()\n",
    "data_other = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 277122 entries, 1 to 354368\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Price              277122 non-null  int64  \n",
      " 1   VehicleType        269647 non-null  object \n",
      " 2   RegistrationYear   277122 non-null  float64\n",
      " 3   Gearbox            273402 non-null  object \n",
      " 4   Power              277122 non-null  float64\n",
      " 5   Model              268379 non-null  object \n",
      " 6   Kilometer          277122 non-null  int64  \n",
      " 7   RegistrationMonth  277122 non-null  float64\n",
      " 8   FuelType           266115 non-null  object \n",
      " 9   Brand              277122 non-null  object \n",
      " 10  NotRepaired        243327 non-null  object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 25.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# для исследования работы пакета LightGBM мы создадим еще один сет для обучения его моделей\n",
    "# в нем будут сохранены пропуски в категориальных данных, но будут удалены все объекты с неявными пропусками в числовых данных\n",
    "data_lgbm_dropfault = data_lgbm.dropna(subset=['Power', 'RegistrationYear', 'RegistrationMonth']).copy()\n",
    "data_lgbm_dropfault.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# категориальные признаки преобразуем в category для сетов lgbm, \n",
    "# для других сетов заполним пропуски новой категорией unknown\n",
    "data_other[columns_category] = data_other[columns_category].fillna('unknown')\n",
    "data_lgbm[columns_category] = data_lgbm[columns_category].astype('category')\n",
    "data_lgbm_dropfault[columns_category] = data_lgbm_dropfault[columns_category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество объектов для обучения LightGBM, категории=category, ошибки и пропуски NaN 341438\n",
      "Количество объектов для обучения LightGBM, категории=category, ошибки удалены        277122\n"
     ]
    }
   ],
   "source": [
    "# подготовка данных для LightGBM завершена\n",
    "X_lgbm = data_lgbm.drop(columns='Price')\n",
    "y_lgbm = data_lgbm['Price']\n",
    "\n",
    "X_lgbm_dropfault = data_lgbm_dropfault.drop(columns='Price')\n",
    "y_lgbm_dropfault = data_lgbm_dropfault['Price']\n",
    "\n",
    "print('Количество объектов для обучения LightGBM, категории=category, ошибки и пропуски NaN', len(X_lgbm))\n",
    "print('Количество объектов для обучения LightGBM, категории=category, ошибки удалены       ', len(X_lgbm_dropfault))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем категориальные данные для обучения других моделей\n",
    "data_other = pd.get_dummies(data_other, columns=columns_category, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас остались пропуски (изначально ошибки) в числовых признаках. Их можно заполнить, либо удалить объекты, содержащие пропуски. Поскольку число пропусков относительно размера набора данных небольшое, можно использовать любой метод. Интересно посмотреть, как повлияет на качество моделей метод работы с пропусками. Создадим два отдельных набора для обучения моделей - с заполненными пропусками и с удаленными пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Kilometer</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>VehicleType_convertible</th>\n",
       "      <th>VehicleType_coupe</th>\n",
       "      <th>VehicleType_other</th>\n",
       "      <th>VehicleType_sedan</th>\n",
       "      <th>VehicleType_small</th>\n",
       "      <th>...</th>\n",
       "      <th>Brand_smart</th>\n",
       "      <th>Brand_sonstige_autos</th>\n",
       "      <th>Brand_subaru</th>\n",
       "      <th>Brand_suzuki</th>\n",
       "      <th>Brand_toyota</th>\n",
       "      <th>Brand_trabant</th>\n",
       "      <th>Brand_volkswagen</th>\n",
       "      <th>Brand_volvo</th>\n",
       "      <th>NotRepaired_unknown</th>\n",
       "      <th>NotRepaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18300</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>125000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9800</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>150000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>90000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354363</th>\n",
       "      <td>1150</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354365</th>\n",
       "      <td>2200</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354366</th>\n",
       "      <td>1199</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>125000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354367</th>\n",
       "      <td>9200</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>150000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354368</th>\n",
       "      <td>3400</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341438 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Price  RegistrationYear  Power  Kilometer  RegistrationMonth  \\\n",
       "0         480            1993.0    NaN     150000                NaN   \n",
       "1       18300            2011.0  190.0     125000                5.0   \n",
       "2        9800            2004.0  163.0     125000                8.0   \n",
       "3        1500            2001.0   75.0     150000                6.0   \n",
       "4        3600            2008.0   69.0      90000                7.0   \n",
       "...       ...               ...    ...        ...                ...   \n",
       "354363   1150            2000.0    NaN     150000                3.0   \n",
       "354365   2200            2005.0    NaN      20000                1.0   \n",
       "354366   1199            2000.0  101.0     125000                3.0   \n",
       "354367   9200            1996.0  102.0     150000                3.0   \n",
       "354368   3400            2002.0  100.0     150000                6.0   \n",
       "\n",
       "        VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
       "0                             0                  0                  0   \n",
       "1                             0                  1                  0   \n",
       "2                             0                  0                  0   \n",
       "3                             0                  0                  0   \n",
       "4                             0                  0                  0   \n",
       "...                         ...                ...                ...   \n",
       "354363                        0                  0                  0   \n",
       "354365                        0                  0                  0   \n",
       "354366                        1                  0                  0   \n",
       "354367                        0                  0                  0   \n",
       "354368                        0                  0                  0   \n",
       "\n",
       "        VehicleType_sedan  VehicleType_small  ...  Brand_smart  \\\n",
       "0                       0                  0  ...            0   \n",
       "1                       0                  0  ...            0   \n",
       "2                       0                  0  ...            0   \n",
       "3                       0                  1  ...            0   \n",
       "4                       0                  1  ...            0   \n",
       "...                   ...                ...  ...          ...   \n",
       "354363                  0                  0  ...            0   \n",
       "354365                  0                  0  ...            0   \n",
       "354366                  0                  0  ...            1   \n",
       "354367                  0                  0  ...            0   \n",
       "354368                  0                  0  ...            0   \n",
       "\n",
       "        Brand_sonstige_autos  Brand_subaru  Brand_suzuki  Brand_toyota  \\\n",
       "0                          0             0             0             0   \n",
       "1                          0             0             0             0   \n",
       "2                          0             0             0             0   \n",
       "3                          0             0             0             0   \n",
       "4                          0             0             0             0   \n",
       "...                      ...           ...           ...           ...   \n",
       "354363                     0             0             0             0   \n",
       "354365                     1             0             0             0   \n",
       "354366                     0             0             0             0   \n",
       "354367                     0             0             0             0   \n",
       "354368                     0             0             0             0   \n",
       "\n",
       "        Brand_trabant  Brand_volkswagen  Brand_volvo  NotRepaired_unknown  \\\n",
       "0                   0                 1            0                    1   \n",
       "1                   0                 0            0                    0   \n",
       "2                   0                 0            0                    1   \n",
       "3                   0                 1            0                    0   \n",
       "4                   0                 0            0                    0   \n",
       "...               ...               ...          ...                  ...   \n",
       "354363              0                 0            0                    0   \n",
       "354365              0                 0            0                    1   \n",
       "354366              0                 0            0                    0   \n",
       "354367              0                 1            0                    0   \n",
       "354368              0                 1            0                    1   \n",
       "\n",
       "        NotRepaired_yes  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "354363                0  \n",
       "354365                0  \n",
       "354366                0  \n",
       "354367                0  \n",
       "354368                0  \n",
       "\n",
       "[341438 rows x 313 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dropfault = data_other.dropna().copy()\n",
    "data_imputed = data_other.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество объектов для обучения Random Forest, категории ohe, ошибки удалены  277122\n",
      "Количество объектов для обучения Random Forest, категории ohe, ошибки заменены 341438\n"
     ]
    }
   ],
   "source": [
    "# подготовка данных для других моделей, в которых удалены все ошибки в числовых признаках, завершена\n",
    "X_dropfault = data_dropfault.drop(columns='Price')\n",
    "y_dropfault = data_dropfault['Price']\n",
    "\n",
    "# в данных для других моделей, в которых мы будем заполнять пропуски, еще надо будет заполнить пропуски, \n",
    "# но мы это сможем сделать только после разбиения данных на обучающую и тестовые выборки\n",
    "X_imputed = data_imputed.drop(columns='Price')\n",
    "y_imputed = data_imputed['Price']\n",
    "\n",
    "print('Количество объектов для обучения Random Forest, категории ohe, ошибки удалены ', len(X_dropfault))\n",
    "print('Количество объектов для обучения Random Forest, категории ohe, ошибки заменены', len(X_imputed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Вывод.\n",
    "- Всего предоставлено 354369 объектов\n",
    "- В числовых признаках, включая целевой, явных пропусков нет. Однако были обнаружены явно ошибочные данные, которые расценены как скрытые пропуски. \n",
    "- Все объекты с неявными пропусками в целевом признаке (цена близка к 0) - их почти 13000 - были удалены. Кроме того, было удалено менее 200 объектов с необычным рассогласованием дат. Найденные неявные пропуски в других числовых столбцах (мощность, год и месяц регистрации) были явно обозначены как NaN.\n",
    "- После изучения столбцов с датами (дата выгрузки анкеты из базы, дата последней активности, дата создания анкеты) было принято решение, что эти признаки не могут влиять на цену и они были удалены. Кроме того, на этом же основании были удалены признаки NumberOfPictures и PostalCode.\n",
    "- Было создано четыре сета данных для обучения моделей:\n",
    "   - Два для обучения моделей LightGBM. Все категориальные признаки в обоих преобразованы в тип category c сохранением пропусков. В одном наборе сохранены неявные пропуски (ошибки) в числовых признаках, количество объектов в нем 341438. В другом наборе такие пропуски удалены (277122 объектов)\n",
    "   - Два для обучения моделей RandomForest. Все категориальные признаки в обоих были заполнены unknown и затем применено кодирование ohe. В одном наборе неявные пропуски (ошибки) в числовых признаках заменены на среднее из обучающего набора, количество объектов в нем 341438. В другом наборе такие пропуски удалены (277122 объектов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 134\n",
    "# будем разбивать начальный набор на train, valid, test\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=RANDOM_STATE)\n",
    "    X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_STATE)\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для сохранения результатов исследования различных моделей создадим df\n",
    "all_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results():\n",
    "    all_results['Assess of overfit'] = ((all_results['RMSE on test'] - all_results['RMSE on train']) / all_results['RMSE on train']).round(2)\n",
    "    display(all_results.sort_values(by='RMSE on test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_RMSE_results(row_name, y_train, y_train_predict, y_valid, y_valid_predict, y_test, y_test_predict):\n",
    "    all_results.loc[row_name, 'RMSE on train'] = round(mean_squared_error(y_train, y_train_predict) ** 0.5, 2)\n",
    "    all_results.loc[row_name, 'RMSE on valid'] = round(mean_squared_error(y_valid, y_valid_predict) ** 0.5, 2)\n",
    "    all_results.loc[row_name, 'RMSE on test'] = round(mean_squared_error(y_test, y_test_predict) ** 0.5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X_lgbm, y_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим результат для dummy модели\n",
    "mean_value = y_train.mean()\n",
    "y_train_predict = pd.Series(mean_value, index=y_train.index)\n",
    "y_valid_predict = pd.Series(mean_value, index=y_valid.index)\n",
    "y_test_predict = pd.Series(mean_value, index=y_test.index)\n",
    "add_RMSE_results('Dummy, single value, mean of y_train', y_train, y_train_predict, y_valid, y_valid_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы преобразовали категориальные данные к типу category, поэтому нет нужды указывать параметр categorical_feature=columns_category\n",
    "def fit_lgbm_regressor(num_leaves, learning_rate, n_estimators, max_bin):\n",
    "    model = lgb.LGBMRegressor(num_leaves=num_leaves, learning_rate=learning_rate, n_estimators=n_estimators, max_bin=max_bin, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train, \n",
    "            eval_set=[(X_valid, y_valid)], \n",
    "            eval_metric='l2', \n",
    "            early_stopping_rounds=5,\n",
    "            verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_lgbm_and_store_results(note_to_name='', num_leaves=31, learning_rate=0.1, n_estimators=100, max_bin=255):\n",
    "    start_time = time.time()\n",
    "    model_gbm = fit_lgbm_regressor(num_leaves, learning_rate, n_estimators, max_bin)\n",
    "    end_time = time.time()\n",
    "    best_iter = model_gbm.best_iteration_\n",
    "    row_name = f'Model LightGBM {note_to_name}, leaves={num_leaves}, learning_rate={learning_rate}, max_bin={max_bin}, best_iteration={best_iter}'\n",
    "    all_results.loc[row_name, 'learning time'] = round(end_time - start_time, 2)\n",
    "    y_train_predict = model_gbm.predict(X_train, num_iteration=best_iter)\n",
    "    y_valid_predict = model_gbm.predict(X_valid, num_iteration=best_iter)\n",
    "    start_time = time.time()\n",
    "    y_test_predict = model_gbm.predict(X_test, num_iteration=best_iter)\n",
    "    end_time = time.time()\n",
    "    all_results.loc[row_name, 'predict time per 1000 object'] = round((end_time - start_time) * 1000 / len(y_test_predict), 3)\n",
    "    add_RMSE_results(row_name, y_train, y_train_predict, y_valid, y_valid_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 9s, sys: 5.66 s, total: 8min 15s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for num_leaves in [31, 70]:\n",
    "    for learning_rate in [0.1, 0.05]:\n",
    "        for max_bin in [255, 2500]:\n",
    "            try_lgbm_and_store_results(num_leaves=num_leaves, learning_rate=learning_rate, n_estimators=5000, max_bin=max_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В таблице модели ранжируются по RMSE на тестовой выборке. Все первые 6 моделей имеют очень близкие показатели точности - RMSE от 1569 до 1586 (разница около 1%). \n",
    "- По скорости обучения и предсказания эти 6 моделей делятся на две группы, по 3 модели в каждой. Скорость и обучения и предсказания отличаются в группах примерно в 2 раза. \n",
    "- По показателю возможной переобученности модели (относительная разность RMSE на обучающей и тестовой выборках) эти 6 моделей также делятся на две группы - в одной показатель 0.13-0.14, в другой 0.17-0.19.\n",
    "- По всем трем параметрам наиболее оптимальной представляется модель со следующими гиперпараметрами:\n",
    "    - num_leaves=31\n",
    "    - max_bin=255\n",
    "    - learning_rate=0.1\n",
    "\n",
    "Эти параметры являются параметрами по умолчанию. С одной стороны это свидетельствует о хорошем качестве дефолтных настроек пакета, с другой стороны обидно, что не удалось превзойти параметры по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1366.97</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>1534.09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1366.97   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1543.10   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...       1534.09   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...           4.03   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.017   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.12  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# зафиксируем наиболее оптимальные гиперпараметры, выявленные на предыдущем этапе\n",
    "num_leaves_best = 31\n",
    "max_bin_best = 255\n",
    "learning_rate_best = 0.1\n",
    "\n",
    "# посмотрим на качество модели при лучших гиперпараметрах, на другом сете, очищенном от неявных пропусков\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X_lgbm_dropfault, y_lgbm_dropfault)\n",
    "try_lgbm_and_store_results(note_to_name=', all NaN in numeric are dropped', \n",
    "                           num_leaves=num_leaves_best, \n",
    "                           learning_rate=learning_rate_best, \n",
    "                           n_estimators=5000, \n",
    "                           max_bin=max_bin_best)\n",
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, избавившись от объектов с NaN в числовых признаках (которые на самом деле представляют из себя ошибки в изначальном наборе данных), мы улучшили все характеристики модели LightGBM с лучшими гиперпараметрами - заметно ускорились, улучшили точность по метрике RMSE на тестовом наборе, так что  модель стала лидирующей по RMSE, и при этом снизилась вероятность переобученности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1366.97</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>1534.09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, all categorical OHE, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=705</th>\n",
       "      <td>1425.96</td>\n",
       "      <td>1568.26</td>\n",
       "      <td>1548.32</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1366.97   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1425.96   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1543.10   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1568.26   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...       1534.09   \n",
       "Model LightGBM , all NaN in numeric are dropped...       1548.32   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...           4.03   \n",
       "Model LightGBM , all NaN in numeric are dropped...           6.68   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.017   \n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.029   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.12  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.09  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# посмотрим на качество модели при самостоятельной обработке категориальных данных\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X_dropfault, y_dropfault)\n",
    "try_lgbm_and_store_results(note_to_name=', all NaN in numeric are dropped, all categorical OHE', \n",
    "                           num_leaves=num_leaves_best, \n",
    "                           learning_rate=learning_rate_best, \n",
    "                           n_estimators=5000, \n",
    "                           max_bin=max_bin_best)\n",
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный результат подтверждает, что внутренний механизм обработки категориальных данных, даже с пропусками, в пакете LightGBM лучше, чем стандартный подход, правильнее сказать, чем стандартный OHE - в рамках данной работы мы не сравнивали с Ordinal Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergeibovdei/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1247: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Brand', 'FuelType', 'Gearbox', 'Model', 'NotRepaired', 'VehicleType']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1366.97</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>1534.09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, all categorical OHE, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=705</th>\n",
       "      <td>1425.96</td>\n",
       "      <td>1568.26</td>\n",
       "      <td>1548.32</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , explicit categorical_feature, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1366.97   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1425.96   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , explicit categorical_feature, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1543.10   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1568.26   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , explicit categorical_feature, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...       1534.09   \n",
       "Model LightGBM , all NaN in numeric are dropped...       1548.32   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , explicit categorical_feature, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...           4.03   \n",
       "Model LightGBM , all NaN in numeric are dropped...           6.68   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , explicit categorical_feature, ...           7.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.017   \n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.029   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , explicit categorical_feature, ...                         0.019   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.12  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.09  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , explicit categorical_feature, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# убедимся, что можно не указывать параметр categorical_feature=columns_category в случае использования типа category pandas\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X_lgbm, y_lgbm)\n",
    "\n",
    "def fit_lgbm_regressor_test(num_leaves, learning_rate, n_estimators, max_bin):\n",
    "    model = lgb.LGBMRegressor(num_leaves=num_leaves, learning_rate=learning_rate, n_estimators=n_estimators, max_bin=max_bin, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train, \n",
    "            eval_set=[(X_valid, y_valid)], \n",
    "            eval_metric='l2', \n",
    "            early_stopping_rounds=5,\n",
    "            categorical_feature=columns_category,\n",
    "            verbose=0)\n",
    "    return model\n",
    "\n",
    "def try_lgbm_and_store_results_test(note_to_name='', num_leaves=31, learning_rate=0.1, n_estimators=100, max_bin=255):\n",
    "    start_time = time.time()\n",
    "    model_gbm = fit_lgbm_regressor_test(num_leaves, learning_rate, n_estimators, max_bin)\n",
    "    end_time = time.time()\n",
    "    best_iter = model_gbm.best_iteration_\n",
    "    row_name = f'Model LightGBM {note_to_name}, leaves={num_leaves}, learning_rate={learning_rate}, max_bin={max_bin}, best_iteration={best_iter}'\n",
    "    all_results.loc[row_name, 'learning time'] = round(end_time - start_time, 2)\n",
    "    y_train_predict = model_gbm.predict(X_train, num_iteration=best_iter)\n",
    "    y_valid_predict = model_gbm.predict(X_valid, num_iteration=best_iter)\n",
    "    start_time = time.time()\n",
    "    y_test_predict = model_gbm.predict(X_test, num_iteration=best_iter)\n",
    "    end_time = time.time()\n",
    "    all_results.loc[row_name, 'predict time per 1000 object'] = round((end_time - start_time) * 1000 / len(y_test_predict), 3)\n",
    "    add_RMSE_results(row_name, y_train, y_train_predict, y_valid, y_valid_predict, y_test, y_test_predict)\n",
    "\n",
    "try_lgbm_and_store_results_test(note_to_name=', explicit categorical_feature', num_leaves=31, learning_rate=.1, n_estimators=5000, max_bin=255)\n",
    "\n",
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще говоря, на официальном сайте LightGBM сказано, что при использовании категориальных данных необходимо указывать параметр categorical_feature явно. Тем не менее, после постоянных получений UserWarning: categorical_feature in Dataset is overridden при использовании данного параметра, были изучены отзывы и советы на других сайтах. В результате было обнаружено утверждение (с подтверждением проверочного кода), что при использовании для категориальных данных типа category pandas нет нужды указывать явно признаки такого типа в параметре categorical_feature. Для гарантии это утверждение было проверено в ячейке выше. \n",
    "\n",
    "Результат этой проверки демонстрирует, что действительно для признаков типа category не надо явно их указывать в параметре categorical_feature - метрика качества не изменилась, лучшая итерация не изменилась, лишь незначительно ухудшилось время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признак kilometer числовой, но его можно расценить и как категориальный с учетом того, что указан не точный пробег, а диапазон\n",
    "# проверим как изменится качество модели, если указать этот признак как категориальный\n",
    "X_lgbm_more_cats = X_lgbm.astype({'Kilometer': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 341438 entries, 0 to 354368\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   VehicleType        308614 non-null  category\n",
      " 1   RegistrationYear   327700 non-null  float64 \n",
      " 2   Gearbox            324901 non-null  category\n",
      " 3   Power              304962 non-null  float64 \n",
      " 4   Model              324338 non-null  category\n",
      " 5   Kilometer          341438 non-null  category\n",
      " 6   RegistrationMonth  299193 non-null  float64 \n",
      " 7   FuelType           312876 non-null  category\n",
      " 8   Brand              341438 non-null  category\n",
      " 9   NotRepaired        276781 non-null  category\n",
      "dtypes: category(7), float64(3)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_lgbm_more_cats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1366.97</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>1534.09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, all categorical OHE, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=705</th>\n",
       "      <td>1425.96</td>\n",
       "      <td>1568.26</td>\n",
       "      <td>1548.32</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , kilometer convert to category, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=769</th>\n",
       "      <td>1375.21</td>\n",
       "      <td>1587.07</td>\n",
       "      <td>1587.55</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , explicit categorical_feature, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , month and year registration convert to category, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1396.36</td>\n",
       "      <td>1599.12</td>\n",
       "      <td>1603.99</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , month and year registration, kilometer convert to category, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=496</th>\n",
       "      <td>1399.24</td>\n",
       "      <td>1602.02</td>\n",
       "      <td>1608.50</td>\n",
       "      <td>5.21</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=17</th>\n",
       "      <td>1256.22</td>\n",
       "      <td>1683.34</td>\n",
       "      <td>1685.85</td>\n",
       "      <td>33.56</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=14</th>\n",
       "      <td>1463.37</td>\n",
       "      <td>1739.57</td>\n",
       "      <td>1739.50</td>\n",
       "      <td>30.69</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=70, max_depth=11</th>\n",
       "      <td>1701.78</td>\n",
       "      <td>1843.76</td>\n",
       "      <td>1833.97</td>\n",
       "      <td>181.87</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=20, max_depth=11</th>\n",
       "      <td>1709.63</td>\n",
       "      <td>1850.34</td>\n",
       "      <td>1841.62</td>\n",
       "      <td>53.15</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=11</th>\n",
       "      <td>1718.91</td>\n",
       "      <td>1859.36</td>\n",
       "      <td>1851.60</td>\n",
       "      <td>28.24</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are imputed by mean, n_estimators=70, max_depth=11</th>\n",
       "      <td>1796.95</td>\n",
       "      <td>1909.38</td>\n",
       "      <td>1907.83</td>\n",
       "      <td>252.94</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=8</th>\n",
       "      <td>1993.83</td>\n",
       "      <td>2052.94</td>\n",
       "      <td>2042.45</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=5</th>\n",
       "      <td>2388.21</td>\n",
       "      <td>2413.41</td>\n",
       "      <td>2398.16</td>\n",
       "      <td>17.63</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1366.97   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1425.96   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , kilometer convert to category,...        1375.21   \n",
       "Model LightGBM , explicit categorical_feature, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , month and year registration co...        1396.36   \n",
       "Model LightGBM , month and year registration, k...        1399.24   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Random forest , all NaN in numeric are dropped,...        1256.22   \n",
       "Random forest , all NaN in numeric are dropped,...        1463.37   \n",
       "Random forest , all NaN in numeric are dropped,...        1701.78   \n",
       "Random forest , all NaN in numeric are dropped,...        1709.63   \n",
       "Random forest , all NaN in numeric are dropped,...        1718.91   \n",
       "Random forest , all NaN in numeric are imputed ...        1796.95   \n",
       "Random forest , all NaN in numeric are dropped,...        1993.83   \n",
       "Random forest , all NaN in numeric are dropped,...        2388.21   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1543.10   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1568.26   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , kilometer convert to category,...        1587.07   \n",
       "Model LightGBM , explicit categorical_feature, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , month and year registration co...        1599.12   \n",
       "Model LightGBM , month and year registration, k...        1602.02   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1683.34   \n",
       "Random forest , all NaN in numeric are dropped,...        1739.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1843.76   \n",
       "Random forest , all NaN in numeric are dropped,...        1850.34   \n",
       "Random forest , all NaN in numeric are dropped,...        1859.36   \n",
       "Random forest , all NaN in numeric are imputed ...        1909.38   \n",
       "Random forest , all NaN in numeric are dropped,...        2052.94   \n",
       "Random forest , all NaN in numeric are dropped,...        2413.41   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...       1534.09   \n",
       "Model LightGBM , all NaN in numeric are dropped...       1548.32   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , kilometer convert to category,...       1587.55   \n",
       "Model LightGBM , explicit categorical_feature, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , month and year registration co...       1603.99   \n",
       "Model LightGBM , month and year registration, k...       1608.50   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Random forest , all NaN in numeric are dropped,...       1685.85   \n",
       "Random forest , all NaN in numeric are dropped,...       1739.50   \n",
       "Random forest , all NaN in numeric are dropped,...       1833.97   \n",
       "Random forest , all NaN in numeric are dropped,...       1841.62   \n",
       "Random forest , all NaN in numeric are dropped,...       1851.60   \n",
       "Random forest , all NaN in numeric are imputed ...       1907.83   \n",
       "Random forest , all NaN in numeric are dropped,...       2042.45   \n",
       "Random forest , all NaN in numeric are dropped,...       2398.16   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...           4.03   \n",
       "Model LightGBM , all NaN in numeric are dropped...           6.68   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , kilometer convert to category,...           6.43   \n",
       "Model LightGBM , explicit categorical_feature, ...           7.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , month and year registration co...           5.31   \n",
       "Model LightGBM , month and year registration, k...           5.21   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Random forest , all NaN in numeric are dropped,...          33.56   \n",
       "Random forest , all NaN in numeric are dropped,...          30.69   \n",
       "Random forest , all NaN in numeric are dropped,...         181.87   \n",
       "Random forest , all NaN in numeric are dropped,...          53.15   \n",
       "Random forest , all NaN in numeric are dropped,...          28.24   \n",
       "Random forest , all NaN in numeric are imputed ...         252.94   \n",
       "Random forest , all NaN in numeric are dropped,...          22.17   \n",
       "Random forest , all NaN in numeric are dropped,...          17.63   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.017   \n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.029   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , kilometer convert to category,...                         0.021   \n",
       "Model LightGBM , explicit categorical_feature, ...                         0.019   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , month and year registration co...                         0.016   \n",
       "Model LightGBM , month and year registration, k...                         0.016   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.010   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are imputed ...                         0.009   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.12  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.09  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , kilometer convert to category,...               0.15  \n",
       "Model LightGBM , explicit categorical_feature, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , month and year registration co...               0.15  \n",
       "Model LightGBM , month and year registration, k...               0.15  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Random forest , all NaN in numeric are dropped,...               0.34  \n",
       "Random forest , all NaN in numeric are dropped,...               0.19  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are imputed ...               0.06  \n",
       "Random forest , all NaN in numeric are dropped,...               0.02  \n",
       "Random forest , all NaN in numeric are dropped,...               0.00  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X_lgbm_more_cats, y_lgbm)\n",
    "try_lgbm_and_store_results(note_to_name=', kilometer convert to category', \n",
    "                           num_leaves=num_leaves_best, \n",
    "                           learning_rate=learning_rate_best, \n",
    "                           n_estimators=5000, \n",
    "                           max_bin=max_bin_best)\n",
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение в метрике несущественное, что, вероятно, объясняется тем, что LightGBM сам работает с числовыми параметрами, как с категориальными (параметр max_bin ограничивает кол-во bins на которые разбивается числовой признак)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X_dropfault, y_dropfault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_rf_and_store_results(note_to_name='', n_estimators=100, max_depth=None):\n",
    "    row_name = f'Random forest {note_to_name}, n_estimators={n_estimators}, max_depth={max_depth}'\n",
    "    start_time = time.time()\n",
    "    model = RandomForestRegressor(random_state=RANDOM_STATE, n_estimators=n_estimators, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    all_results.loc[row_name, 'learning time'] = round(end_time - start_time, 2)\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_valid_predict = model.predict(X_valid)\n",
    "    start_time = time.time()\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    all_results.loc[row_name, 'predict time per 1000 object'] = round((end_time - start_time) * 1000 / len(y_test_predict), 3)\n",
    "    add_RMSE_results(row_name, y_train, y_train_predict, y_valid, y_valid_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 3.22 s, total: 2min 16s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# сначала определим оптимальную глубину решающего дерева\n",
    "for max_depth in [5, 8, 11, 14, 17]:\n",
    "    for n_estimators in [10]:\n",
    "        try_rf_and_store_results(note_to_name=', all NaN in numeric are dropped', n_estimators=n_estimators, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1366.97</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>1534.09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, all categorical OHE, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=705</th>\n",
       "      <td>1425.96</td>\n",
       "      <td>1568.26</td>\n",
       "      <td>1548.32</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , explicit categorical_feature, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=17</th>\n",
       "      <td>1256.22</td>\n",
       "      <td>1683.34</td>\n",
       "      <td>1685.85</td>\n",
       "      <td>33.56</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=14</th>\n",
       "      <td>1463.37</td>\n",
       "      <td>1739.57</td>\n",
       "      <td>1739.50</td>\n",
       "      <td>30.69</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=11</th>\n",
       "      <td>1718.91</td>\n",
       "      <td>1859.36</td>\n",
       "      <td>1851.60</td>\n",
       "      <td>28.24</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=8</th>\n",
       "      <td>1993.83</td>\n",
       "      <td>2052.94</td>\n",
       "      <td>2042.45</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=5</th>\n",
       "      <td>2388.21</td>\n",
       "      <td>2413.41</td>\n",
       "      <td>2398.16</td>\n",
       "      <td>17.63</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1366.97   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1425.96   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , explicit categorical_feature, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Random forest , all NaN in numeric are dropped,...        1256.22   \n",
       "Random forest , all NaN in numeric are dropped,...        1463.37   \n",
       "Random forest , all NaN in numeric are dropped,...        1718.91   \n",
       "Random forest , all NaN in numeric are dropped,...        1993.83   \n",
       "Random forest , all NaN in numeric are dropped,...        2388.21   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1543.10   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1568.26   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , explicit categorical_feature, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1683.34   \n",
       "Random forest , all NaN in numeric are dropped,...        1739.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1859.36   \n",
       "Random forest , all NaN in numeric are dropped,...        2052.94   \n",
       "Random forest , all NaN in numeric are dropped,...        2413.41   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...       1534.09   \n",
       "Model LightGBM , all NaN in numeric are dropped...       1548.32   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , explicit categorical_feature, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Random forest , all NaN in numeric are dropped,...       1685.85   \n",
       "Random forest , all NaN in numeric are dropped,...       1739.50   \n",
       "Random forest , all NaN in numeric are dropped,...       1851.60   \n",
       "Random forest , all NaN in numeric are dropped,...       2042.45   \n",
       "Random forest , all NaN in numeric are dropped,...       2398.16   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...           4.03   \n",
       "Model LightGBM , all NaN in numeric are dropped...           6.68   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , explicit categorical_feature, ...           7.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Random forest , all NaN in numeric are dropped,...          33.56   \n",
       "Random forest , all NaN in numeric are dropped,...          30.69   \n",
       "Random forest , all NaN in numeric are dropped,...          28.24   \n",
       "Random forest , all NaN in numeric are dropped,...          22.17   \n",
       "Random forest , all NaN in numeric are dropped,...          17.63   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.017   \n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.029   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , explicit categorical_feature, ...                         0.019   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.12  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.09  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , explicit categorical_feature, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Random forest , all NaN in numeric are dropped,...               0.34  \n",
       "Random forest , all NaN in numeric are dropped,...               0.19  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.02  \n",
       "Random forest , all NaN in numeric are dropped,...               0.00  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 57s, sys: 1.42 s, total: 3min 58s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# модели с глубиной дерева 14 и 17 явно переобучаются, глубина 5 - явно недообученная, 8 скорее всего тоже, \n",
    "# останавливаемся на 11\n",
    "# время обучения случайного леса велико, поэтому в настоящей работе не будем сильно увеличивать кол-во оценщиков \n",
    "for max_depth in [11]:\n",
    "    for n_estimators in [20, 70]:\n",
    "        try_rf_and_store_results(note_to_name=', all NaN in numeric are dropped', n_estimators=n_estimators, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1366.97</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>1534.09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, all categorical OHE, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=705</th>\n",
       "      <td>1425.96</td>\n",
       "      <td>1568.26</td>\n",
       "      <td>1548.32</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , explicit categorical_feature, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=17</th>\n",
       "      <td>1256.22</td>\n",
       "      <td>1683.34</td>\n",
       "      <td>1685.85</td>\n",
       "      <td>33.56</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=14</th>\n",
       "      <td>1463.37</td>\n",
       "      <td>1739.57</td>\n",
       "      <td>1739.50</td>\n",
       "      <td>30.69</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=70, max_depth=11</th>\n",
       "      <td>1701.78</td>\n",
       "      <td>1843.76</td>\n",
       "      <td>1833.97</td>\n",
       "      <td>181.87</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=20, max_depth=11</th>\n",
       "      <td>1709.63</td>\n",
       "      <td>1850.34</td>\n",
       "      <td>1841.62</td>\n",
       "      <td>53.15</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=11</th>\n",
       "      <td>1718.91</td>\n",
       "      <td>1859.36</td>\n",
       "      <td>1851.60</td>\n",
       "      <td>28.24</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=8</th>\n",
       "      <td>1993.83</td>\n",
       "      <td>2052.94</td>\n",
       "      <td>2042.45</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=5</th>\n",
       "      <td>2388.21</td>\n",
       "      <td>2413.41</td>\n",
       "      <td>2398.16</td>\n",
       "      <td>17.63</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1366.97   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1425.96   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , explicit categorical_feature, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Random forest , all NaN in numeric are dropped,...        1256.22   \n",
       "Random forest , all NaN in numeric are dropped,...        1463.37   \n",
       "Random forest , all NaN in numeric are dropped,...        1701.78   \n",
       "Random forest , all NaN in numeric are dropped,...        1709.63   \n",
       "Random forest , all NaN in numeric are dropped,...        1718.91   \n",
       "Random forest , all NaN in numeric are dropped,...        1993.83   \n",
       "Random forest , all NaN in numeric are dropped,...        2388.21   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1543.10   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1568.26   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , explicit categorical_feature, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1683.34   \n",
       "Random forest , all NaN in numeric are dropped,...        1739.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1843.76   \n",
       "Random forest , all NaN in numeric are dropped,...        1850.34   \n",
       "Random forest , all NaN in numeric are dropped,...        1859.36   \n",
       "Random forest , all NaN in numeric are dropped,...        2052.94   \n",
       "Random forest , all NaN in numeric are dropped,...        2413.41   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...       1534.09   \n",
       "Model LightGBM , all NaN in numeric are dropped...       1548.32   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , explicit categorical_feature, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Random forest , all NaN in numeric are dropped,...       1685.85   \n",
       "Random forest , all NaN in numeric are dropped,...       1739.50   \n",
       "Random forest , all NaN in numeric are dropped,...       1833.97   \n",
       "Random forest , all NaN in numeric are dropped,...       1841.62   \n",
       "Random forest , all NaN in numeric are dropped,...       1851.60   \n",
       "Random forest , all NaN in numeric are dropped,...       2042.45   \n",
       "Random forest , all NaN in numeric are dropped,...       2398.16   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...           4.03   \n",
       "Model LightGBM , all NaN in numeric are dropped...           6.68   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , explicit categorical_feature, ...           7.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Random forest , all NaN in numeric are dropped,...          33.56   \n",
       "Random forest , all NaN in numeric are dropped,...          30.69   \n",
       "Random forest , all NaN in numeric are dropped,...         181.87   \n",
       "Random forest , all NaN in numeric are dropped,...          53.15   \n",
       "Random forest , all NaN in numeric are dropped,...          28.24   \n",
       "Random forest , all NaN in numeric are dropped,...          22.17   \n",
       "Random forest , all NaN in numeric are dropped,...          17.63   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.017   \n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.029   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , explicit categorical_feature, ...                         0.019   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.010   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.12  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.09  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , explicit categorical_feature, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Random forest , all NaN in numeric are dropped,...               0.34  \n",
       "Random forest , all NaN in numeric are dropped,...               0.19  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.02  \n",
       "Random forest , all NaN in numeric are dropped,...               0.00  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ожидаемо с увеличением кол-ва деревьев в лесе увеличивается и точность прогноза по RMSE. Судя по динамике изменения RMSE, скорее всего, для увеличения точности можно еще увеличить кол-во дереьев, однако при этом увеличится и так громадное по сравнению с LightGBM время обучения - случайный лес с 70 оценщиками обучается в 40 раз медленнее, чем лучший LightGBM на таком же наборе данных. \n",
    "- При этом точность леса с 70 оценщиками по RMSE не достигла даже результатов худшей модели LightGBM, проигрыш же по RMSE лучшей модели LightGBM составил почти 20%.\n",
    "- Важное отличие случайного леса от LightGBM - несмотря на очень существенный проигрыш во времени обучения, время предсказания для обученной модели почти в 2 раза лучше, чем у лучшей по всем параметрам модели LightGBM. При этом однако сопоставимая по времени предсказания модель LightGBM лучше модели случайного леса по времени обучения в 50-60 раз и по точности по RMSE лучше почти на 15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оценим качество случайного леса при заполнении пропусков средними по выборке X_train\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X_imputed, y_imputed)\n",
    "\n",
    "imputed_mean = SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
    "imputed_mean.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputed_mean.transform(X_train)\n",
    "X_valid = imputed_mean.transform(X_valid)\n",
    "X_test = imputed_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_rf_and_store_results(note_to_name=', all NaN in numeric are imputed by mean', n_estimators=70, max_depth=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE on train</th>\n",
       "      <th>RMSE on valid</th>\n",
       "      <th>RMSE on test</th>\n",
       "      <th>learning time</th>\n",
       "      <th>predict time per 1000 object</th>\n",
       "      <th>Assess of overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=517</th>\n",
       "      <td>1366.97</td>\n",
       "      <td>1543.10</td>\n",
       "      <td>1534.09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , all NaN in numeric are dropped, all categorical OHE, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=705</th>\n",
       "      <td>1425.96</td>\n",
       "      <td>1568.26</td>\n",
       "      <td>1548.32</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=2500, best_iteration=912</th>\n",
       "      <td>1323.91</td>\n",
       "      <td>1569.67</td>\n",
       "      <td>1569.01</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.05, max_bin=255, best_iteration=796</th>\n",
       "      <td>1345.11</td>\n",
       "      <td>1573.99</td>\n",
       "      <td>1572.74</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=255, best_iteration=457</th>\n",
       "      <td>1332.06</td>\n",
       "      <td>1578.56</td>\n",
       "      <td>1575.66</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=70, learning_rate=0.1, max_bin=2500, best_iteration=385</th>\n",
       "      <td>1354.52</td>\n",
       "      <td>1580.68</td>\n",
       "      <td>1579.58</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=2500, best_iteration=1287</th>\n",
       "      <td>1398.74</td>\n",
       "      <td>1587.69</td>\n",
       "      <td>1586.03</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , explicit categorical_feature, leaves=31, learning_rate=0.1, max_bin=255, best_iteration=687</th>\n",
       "      <td>1397.83</td>\n",
       "      <td>1591.88</td>\n",
       "      <td>1589.23</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.1, max_bin=2500, best_iteration=315</th>\n",
       "      <td>1490.65</td>\n",
       "      <td>1618.55</td>\n",
       "      <td>1619.85</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model LightGBM , leaves=31, learning_rate=0.05, max_bin=255, best_iteration=431</th>\n",
       "      <td>1531.74</td>\n",
       "      <td>1633.57</td>\n",
       "      <td>1634.90</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=17</th>\n",
       "      <td>1256.22</td>\n",
       "      <td>1683.34</td>\n",
       "      <td>1685.85</td>\n",
       "      <td>33.56</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=14</th>\n",
       "      <td>1463.37</td>\n",
       "      <td>1739.57</td>\n",
       "      <td>1739.50</td>\n",
       "      <td>30.69</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=70, max_depth=11</th>\n",
       "      <td>1701.78</td>\n",
       "      <td>1843.76</td>\n",
       "      <td>1833.97</td>\n",
       "      <td>181.87</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=20, max_depth=11</th>\n",
       "      <td>1709.63</td>\n",
       "      <td>1850.34</td>\n",
       "      <td>1841.62</td>\n",
       "      <td>53.15</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=11</th>\n",
       "      <td>1718.91</td>\n",
       "      <td>1859.36</td>\n",
       "      <td>1851.60</td>\n",
       "      <td>28.24</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are imputed by mean, n_estimators=70, max_depth=11</th>\n",
       "      <td>1796.95</td>\n",
       "      <td>1909.38</td>\n",
       "      <td>1907.83</td>\n",
       "      <td>252.94</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=8</th>\n",
       "      <td>1993.83</td>\n",
       "      <td>2052.94</td>\n",
       "      <td>2042.45</td>\n",
       "      <td>22.17</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest , all NaN in numeric are dropped, n_estimators=10, max_depth=5</th>\n",
       "      <td>2388.21</td>\n",
       "      <td>2413.41</td>\n",
       "      <td>2398.16</td>\n",
       "      <td>17.63</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy, single value, mean of y_train</th>\n",
       "      <td>4511.53</td>\n",
       "      <td>4522.83</td>\n",
       "      <td>4514.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    RMSE on train  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1366.97   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1425.96   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1323.91   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1345.11   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1332.06   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1354.52   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1398.74   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1397.83   \n",
       "Model LightGBM , explicit categorical_feature, ...        1397.83   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1490.65   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1531.74   \n",
       "Random forest , all NaN in numeric are dropped,...        1256.22   \n",
       "Random forest , all NaN in numeric are dropped,...        1463.37   \n",
       "Random forest , all NaN in numeric are dropped,...        1701.78   \n",
       "Random forest , all NaN in numeric are dropped,...        1709.63   \n",
       "Random forest , all NaN in numeric are dropped,...        1718.91   \n",
       "Random forest , all NaN in numeric are imputed ...        1796.95   \n",
       "Random forest , all NaN in numeric are dropped,...        1993.83   \n",
       "Random forest , all NaN in numeric are dropped,...        2388.21   \n",
       "Dummy, single value, mean of y_train                      4511.53   \n",
       "\n",
       "                                                    RMSE on valid  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...        1543.10   \n",
       "Model LightGBM , all NaN in numeric are dropped...        1568.26   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1569.67   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...        1573.99   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1578.56   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...        1580.68   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1587.69   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1591.88   \n",
       "Model LightGBM , explicit categorical_feature, ...        1591.88   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...        1618.55   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...        1633.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1683.34   \n",
       "Random forest , all NaN in numeric are dropped,...        1739.57   \n",
       "Random forest , all NaN in numeric are dropped,...        1843.76   \n",
       "Random forest , all NaN in numeric are dropped,...        1850.34   \n",
       "Random forest , all NaN in numeric are dropped,...        1859.36   \n",
       "Random forest , all NaN in numeric are imputed ...        1909.38   \n",
       "Random forest , all NaN in numeric are dropped,...        2052.94   \n",
       "Random forest , all NaN in numeric are dropped,...        2413.41   \n",
       "Dummy, single value, mean of y_train                      4522.83   \n",
       "\n",
       "                                                    RMSE on test  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...       1534.09   \n",
       "Model LightGBM , all NaN in numeric are dropped...       1548.32   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1569.01   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...       1572.74   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1575.66   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...       1579.58   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1586.03   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1589.23   \n",
       "Model LightGBM , explicit categorical_feature, ...       1589.23   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...       1619.85   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...       1634.90   \n",
       "Random forest , all NaN in numeric are dropped,...       1685.85   \n",
       "Random forest , all NaN in numeric are dropped,...       1739.50   \n",
       "Random forest , all NaN in numeric are dropped,...       1833.97   \n",
       "Random forest , all NaN in numeric are dropped,...       1841.62   \n",
       "Random forest , all NaN in numeric are dropped,...       1851.60   \n",
       "Random forest , all NaN in numeric are imputed ...       1907.83   \n",
       "Random forest , all NaN in numeric are dropped,...       2042.45   \n",
       "Random forest , all NaN in numeric are dropped,...       2398.16   \n",
       "Dummy, single value, mean of y_train                     4514.00   \n",
       "\n",
       "                                                    learning time  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...           4.03   \n",
       "Model LightGBM , all NaN in numeric are dropped...           6.68   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...          11.85   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...           9.80   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.76   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...           5.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...          12.79   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           6.90   \n",
       "Model LightGBM , explicit categorical_feature, ...           7.15   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...           3.87   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...           5.15   \n",
       "Random forest , all NaN in numeric are dropped,...          33.56   \n",
       "Random forest , all NaN in numeric are dropped,...          30.69   \n",
       "Random forest , all NaN in numeric are dropped,...         181.87   \n",
       "Random forest , all NaN in numeric are dropped,...          53.15   \n",
       "Random forest , all NaN in numeric are dropped,...          28.24   \n",
       "Random forest , all NaN in numeric are imputed ...         252.94   \n",
       "Random forest , all NaN in numeric are dropped,...          22.17   \n",
       "Random forest , all NaN in numeric are dropped,...          17.63   \n",
       "Dummy, single value, mean of y_train                          NaN   \n",
       "\n",
       "                                                    predict time per 1000 object  \\\n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.017   \n",
       "Model LightGBM , all NaN in numeric are dropped...                         0.029   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...                         0.035   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.019   \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...                         0.020   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.039   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.027   \n",
       "Model LightGBM , explicit categorical_feature, ...                         0.019   \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...                         0.012   \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...                         0.020   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.010   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.004   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are imputed ...                         0.009   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Random forest , all NaN in numeric are dropped,...                         0.003   \n",
       "Dummy, single value, mean of y_train                                         NaN   \n",
       "\n",
       "                                                    Assess of overfit  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.12  \n",
       "Model LightGBM , all NaN in numeric are dropped...               0.09  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.19  \n",
       "Model LightGBM , leaves=70, learning_rate=0.05,...               0.17  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.18  \n",
       "Model LightGBM , leaves=70, learning_rate=0.1, ...               0.17  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.13  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.14  \n",
       "Model LightGBM , explicit categorical_feature, ...               0.14  \n",
       "Model LightGBM , leaves=31, learning_rate=0.1, ...               0.09  \n",
       "Model LightGBM , leaves=31, learning_rate=0.05,...               0.07  \n",
       "Random forest , all NaN in numeric are dropped,...               0.34  \n",
       "Random forest , all NaN in numeric are dropped,...               0.19  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are dropped,...               0.08  \n",
       "Random forest , all NaN in numeric are imputed ...               0.06  \n",
       "Random forest , all NaN in numeric are dropped,...               0.02  \n",
       "Random forest , all NaN in numeric are dropped,...               0.00  \n",
       "Dummy, single value, mean of y_train                             0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, обученная на очищенном от неявных пропусков в числовых признаках дэйтасете, продемонстрировала лучший результат по RMSE по сравнению с моделью, обученной на данных с заполнением пропусков средними значениями из обучающего набора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы.\n",
    "- Были исследованы различные модели градиентного бустинга библиотеки LightGBM. Модели сравнивались по точности RMSE, по времени обучения и предсказания, по критерию возможной переобученности. Наилучшими гиперпараметрами, при которых модель LightGBM достигла наилучшего совокупного результата по изложенным выше критериям, оказались параметры по умолчанию:\n",
    "    - num_leaves=31\n",
    "    - max_bin=255\n",
    "    - learning_rate=0.1\n",
    "\n",
    "- Вариация гиперпараметров производилась на наборе данных, в котором были сохранены все обнаруженные на этапе препроцессинга неявные пропуски как в числовых признаках, так и в категориальных (им были присвоены значения np.NaN), поскольку библиотека LightGBM декларирует самостоятельную эффективную обработку пропусков. Дополнительно, для сравнения были обучены модели на данных, в которых а) были удалены объекты с пропусками в числовых данных, но сохранены пропуски в категориальных данных и б) были удалены объекты с пропусками в числовых данных, пропуски в категориальных данных были заполнены unknown и затем проведено кодирование по ohe. Удаление объектов с NaN в числовых признаках с сохранением неизменными категориальных признаков (без заполнения unknown и без ohe) позволило получить наилучшую модель - заметно ускорились и обучение и предсказание, точность по метрике RMSE на тестовом/валидационном наборе стала лучшей среди всех исследованных моделей. \n",
    "\n",
    "- Также было продемонстрировано, что библиотека LightGBM отлично справляется с категориальными данными (и с  пропусками в них), заполнения пропусков в таких признаках и использование ohe лишь ухудшает скорость и точность моделей.\n",
    "\n",
    "- Для сравнением с градиентным бустингом библиотеки LightGBM были исследованы различные модели случайного леса. Были получены оптимальные параметры максимальной глубины (11 уровней) и наилучшей моделью по кол-ву оценщиков оказалась модель с 70 оценщиками, но это кол-во было максимальным из исследованных. Судя по динамике изменения RMSE, скорее всего, для увеличения точности можно было еще увеличить кол-во деревьев, однако при этом увеличилось бы и так громадное по сравнению с LightGBM время обучения - случайный лес с 70 оценщиками обучался в 40 раз медленнее, чем лучший LightGBM на таком же наборе данных. \n",
    "- При этом точность леса с 70 оценщиками по RMSE не достигла даже результатов худшей модели LightGBM, проигрыш же по RMSE лучшей модели LightGBM составил почти 20%. Важное отличие случайного леса от LightGBM - несмотря на очень существенный проигрыш во времени обучения, время предсказания для обученной модели почти в 2 раза лучше, чем у лучшей по всем параметрам модели LightGBM. При этом однако сопоставимая по времени предсказания модель LightGBM лучше модели случайного леса по времени обучения в 50-60 раз и по точности по RMSE лучше почти на 15%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Выполнена загрузка и подготовка данных\n",
    "- [x]  Выполнено обучение моделей\n",
    "- [x]  Есть анализ скорости работы и качества моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
